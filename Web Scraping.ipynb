{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scraping data from web, we use \"BeautifulSoup\" library in Python. But, sometimes \"BeautifulSoup\" fails to retreive desired data because the web page adds data with the help of javascript. \n",
    "\n",
    "Here, Selenium comes into picture which can handle web pages more adequately.\n",
    "\n",
    "Firstly, we need to install \"selenium\" library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\abhay\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\abhay\\anaconda3\\lib\\site-packages (from selenium) (1.24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this we need to import packages that we're going to use in this small piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For retreiving data from website we need to open that web page. \n",
    "\n",
    "Note: If you are using Chrome Version 83.x.xxxx.xxx, download compatiable chromedriver from \"https://chromedriver.chromium.org/downloads\". After that import above cell packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the websites follow a simple pattern of paging, so you can observe the pattern and create a 'for' loop as follows.\n",
    "\n",
    "Note: webdriver.Chrome() creates a new automated instance of Chrome in which your desired page will get opened. Moreover, 'chromedriver' works with 'Google Chrome' only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After opening your website, with help of this code; in a new automated instance of Chrome, press 'Ctrl + Shift + I'.\n",
    "This will open inspect page for website. \n",
    "You need to right click on related HTML tag and copy XML path (XPath) from there and paste it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retreiving data from page :  1\n",
      "Retreiving data from page :  2\n",
      "Retreiving data from page :  3\n",
      "Retreiving data from page :  4\n",
      "Retreiving data from page :  5\n",
      "Retreiving data from page :  6\n",
      "Retreiving data from page :  7\n",
      "Retreiving data from page :  8\n",
      "Retreiving data from page :  9\n",
      "Retreiving data from page :  10\n",
      "Retreiving data from page :  11\n",
      "Retreiving data from page :  12\n",
      "Retreiving data from page :  13\n",
      "Retreiving data from page :  14\n",
      "Retreiving data from page :  15\n",
      "Retreiving data from page :  16\n",
      "Retreiving data from page :  17\n",
      "Retreiving data from page :  18\n",
      "Retreiving data from page :  19\n",
      "Retreiving data from page :  20\n",
      "Retreiving data from page :  21\n",
      "Retreiving data from page :  22\n",
      "Retreiving data from page :  23\n",
      "Retreiving data from page :  24\n",
      "Retreiving data from page :  25\n",
      "Retreiving data from page :  26\n",
      "Retreiving data from page :  27\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "api_names = []\n",
    "links = []\n",
    "discription = []\n",
    "\n",
    "try:\n",
    "    for n in range(1, 29):\n",
    "        driver.get('Your desired link here' + str(n))\n",
    "        sleep(10)\n",
    "        for i in range(24):\n",
    "            #extract user id using XPath of the same\n",
    "            userid_element = driver.find_elements_by_xpath('//*[@id=\"api_item_undefined\"]/div[1]/div')[i]\n",
    "            api_names.append(userid_element.text)\n",
    "            sleep(1)\n",
    "            \n",
    "            #extract hyperlink using XPath of the same\n",
    "            href_element = driver.find_elements_by_xpath('//*[@id=\"api_item_undefined\"]')[i]\n",
    "            links.append(href_element.get_attribute('href'))\n",
    "            sleep(1)\n",
    "            \n",
    "            #extract discription using XPath of the same\n",
    "            disc = driver.find_elements_by_xpath('//*[@id=\"api_item_undefined\"]/div[2]/div')[i]\n",
    "            discription.append(disc.text)\n",
    "            sleep(1)\n",
    "            \n",
    "        #for tracking of progress\n",
    "        print(\"Retreiving data from page : \", n)\n",
    "except:\n",
    "    print(\"Finished\")\n",
    "        \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all the data is extracted and assigned to list variables created above, use NumPy to create array vectors and then make a DataFrame as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = []\n",
    "\n",
    "for i in range(len(api_names)):\n",
    "    A.append(i+1)\n",
    "    \n",
    "df = pd.DataFrame(A, columns = [\"Serial\"])\n",
    "df[\"API Name\"] = np.array(api_names)\n",
    "df[\"Link\"] = np.array(links)\n",
    "df[\"Discription\"] = np.array(discription)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your DataFrame as CSV file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"API Details.csv\", index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
